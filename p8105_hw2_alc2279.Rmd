---
title: "p8105_hw2_alc2279"
author: "Annie Clark"
date: "September 29, 2018"
output: github_document
---
General questions - do we need to print everything? even when we just load/clean data?


#Problem 0
This “problem” focuses on structure of your submission, especially the use git and GitHub for reproducibility, R Projects to organize your work, R Markdown to write reproducible reports, relative paths to load data from local files, and reasonable naming structures for your files.

To that end:

* create a public GitHub repo + local R Project; we suggest naming this repo / directory
p8105_hw2_YOURUNI (e.g.  p8105_hw2_ajg2202 for Jeff), but that’s not required
* create a single .Rmd file named p8105_hw2_YOURUNI.Rmd that renders to github_document
* create a subdirectory to store the local data files used in Problems 1 and 2, and use 
relative paths to access these data files
* Your solutions to Problems 1, 2, and 3 should be implemented in your .Rmd file, 
and your git commit history should reflect the process you used to solve these Problems.

For this Problem, we will assess adherence to the instructions above regarding repo structure, git commit history, and whether we are able to knit your .Rmd to ensure that your work is reproducible. Adherence to appropriate styling and clarity of code will be assessed in Problems 1+.

#Problem 1
##Part 1: Read and clean data
This problem focuses on NYC Transit data; in particular, this CSV file contains information related to each entrance and exit for each subway station in NYC.

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

```{r}
library(tidyverse)

subway_data = 
  read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>% 
  mutate(entry = recode(entry, "YES" = 1, "NO" = 0),
         entry = as.logical(entry))

##Question - (1) as.logical and recode on same line? (2) better way to go char->log?
```

##Part 2: Describe dataset
Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?



##Part 3: Answer some questions

* How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1; 125st 4/5); the distinct function may be useful here.

```{r}
nrow(distinct(subway_data, station_name, line))

##Question - the "line" in the dataset is not A/B/C/D; rather it's lexington, 4th ave, etc. 
##Question - nrow and function on one line? any way to make more simple?
```

* How many stations are ADA compliant?

```{r}
nrow(filter(subway_data, ada == TRUE))
```

* What proportion of station entrances / exits without vending allow entrance?

```{r}
#find number of entrances/exits with no vending and entry
entry_no_vending = nrow(filter(subway_data, vending == "NO", entry == TRUE))

#find total number of entrances/exits
all_entrances_exits = nrow(subway_data)

#find proportion
entry_no_vending / all_entrances_exits
```


##Part 4: Another exericse
Reformat data so that route number and route name are distinct variables. 
```{r}
subway_data =  
  gather(subway_data, key = route_num, value = route_name, route1:route11) %>% 
  separate(route_num, into = c("route", "route_num"), sep = 5) %>%
  select(line:ada, route_num, route_name)
```

How many distinct stations serve the A train?

```{r}
a_train_stations = filter(subway_data, route_name == "A")

nrow(distinct(a_train_stations, station_name))

##Questin - I created a new dataset -- is there a way to use piping for this?
```

Of the stations that serve the A train, how many are ADA compliant?

```{r}
nrow(filter(a_train_stations, ada == TRUE))

##Question - used new dataset - is there a way to use piping?
```

#Problem 2

##Part 1: Read and clean data
This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website. Please use the  HealthyHarborWaterWheelTotals2017-9-26.xlsx version.

Read and clean the Mr. Trash Wheel sheet:

* specify the sheet in the Excel file and to omit columns containing notes (using the range argument and cell_cols() function)
* use reasonable variable names
* omit rows that do not include dumpster-specific data
* round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
library(readxl)

water_wheel_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = "Mr. Trash Wheel",
                              range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster),
         month != "Grand Total") %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))

#Question - should my filtering be more elegant? rounding and as integer on different lines?
##question - read_excel on multiple lines? doesnt' look pretty
?read_excel
```

Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. 

```{r}
precipitation_2016_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = "2016 Precipitation",
                              range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2016")

precipitation_2017_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                              sheet = "2017 Precipitation",
                              range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  mutate(year = "2017")

##Question - can I just use the range? or do i need to use cell_cols and omit?
##question - for 2017, load all months? even those with null values?
```

Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

```{r}
precipitation_data = bind_rows(precipitation_2016_data, precipitation_2017_data) %>% 
  mutate(month = month.name[month])
```

##Part 2: Describe dataset
Write a paragraph about these data; you are encouraged to use inline R. Be sure to note:
* the number of observations in both resulting datasets
* give examples of key variables
For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

```{r}

```

#Problem 3

##Part 1: Read and clean data
This problem uses the BRFSS data. DO NOT include this dataset in your local data directory; instead, load the data from the  p8105.datasets package.

For this question:

* format the data to use appropriate variable names
* focus on the “Overall Health” topic
* exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
* structure data so that responses (excellent to poor) are variables taking the value of Data_value
* create a new variable showing the proportion of responses that were “Excellent” or “Very Good”

```{r}
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  select(year:county, excellent, very_good, good, fair, poor) %>% 
  mutate(high_response_proportion = (excellent + very_good) / 
           (excellent + very_good + good + fair + poor))

##Question - exclude or can i just include the 5 variables?
##Question - is there a more elegant way to do the proportion?
##Quetion - high_reponse_proportion - can i figure out a better name for this?
```

##Part 2: Answer some questions
Using this dataset, do or answer the following:

* How many unique locations are included in the dataset? Is every state represented? What state is observed the most?

```{r}
brfss_data_test = 
  mutate(brfss_data, concat = paste(state, county, sep = '-'))

nrow(distinct(brfss_data, county))

##Question - can I assume that state is always the same? if not, is there another way than creating a new dataset?

nrow(distinct(brfss_data, state))

##Question - can we assume that all 50 states are represented because gives 51 and DC is in there? Do we need to go check?

brfss_data %>% 
  count(state) %>% 
  arrange(desc(n))

```

* In 2002, what is the median of the “Excellent” response value?

```{r}
brfss_2002_data = 
  brfss_data %>%
  filter(year == 2002)

median(brfss_2002_data$excellent, na.rm = TRUE)

#Question - create new dataset??????? is there a way to pipe into median?
```

* Make a histogram of “Excellent” response values in the year 2002.

```{r}
ggplot(brfss_2002_data, aes(x = excellent)) + 
  geom_histogram()
```

* Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r}
brfss_queens_ny_data = 
  brfss_data %>%
  filter(county %in% c("NY - Queens County", "NY - New York County")) %>% 
  mutate(excellent_proportion = excellent / (excellent + very_good + good + fair + poor))

ggplot(brfss_queens_ny_data, aes(x = year, y = excellent_proportion)) + 
  geom_point(aes(color = county))

```

